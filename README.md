# Transformer
> Simple implementation of the traditional transformer from scratch.
> 
> Altered from https://nlp.seas.harvard.edu/2018/04/03/attention.html

## TODO
- Add training script & comments for optimizer.

